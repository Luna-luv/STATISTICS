# 통계학 6주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_6th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

6주차는 `3부. 데이터 분석하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_6th_TIL

### 3부. 데이터 분석하기
### 12.통계 기반 분석 방법론



## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | ✅      | 
|3주차| 2부 p.82~120   | ✅      | 
|4주차| 2부 p.121~202  | ✅      | 
|5주차| 2부 p.203~254  | ✅      | 
|6주차| 3부 p.300~356  | ✅      | 
|7주차| 3부 p.357~615  | 🍽️      |

<!-- 여기까진 그대로 둬 주세요-->

# 12.통계 기반 분석 방법론

```
✅ 학습 목표 :
* 주성분 분석(PCA)의 개념을 설명할 수 있다.
* 다중공선성을 진단할 수 있다.
* Z-TEST와 T-TEST의 개념을 비교하고, 적절한 상황에서 검정을 설계하고 수행할 수 있다.
* ANOVA TEST를 활용하여 세 개 이상의 그룹 간 평균 차이를 검정하고, 사후검정을 수행할 수 있다.
* 카이제곱 검정을 통해 범주형 변수 간의 독립성과 연관성을 분석하는 방법을 설명할 수 있다.
```

## 12.1. 분석 모델 개요
#### 통계모델 vs 기계학습 

| 구분         | 통계 모델                         | 기계 학습          |
| ---------- | ----------------------------- | -------------- |
| **목적**     | 모형을 통한 **현상 해석** · 오차·불확실성 규명 | **예측 정확도** 최우선 |
| **데이터 규모** | 비교적 소규모여도 가능                  | 대용량 데이터 활용 ↑   |
| **접근법**    | 가설 설정 → 검정                    | 패턴 학습 → 일반화    |
| **복잡성**    | 단순·해석 용이                      | 복잡·비선형 구조 지원   |

(1) 통계모델
- Z-test : 모분산(또는 σ) 알려진 대표본·비율 검정
- T-test : 모분산 미지, 소표본 평균 비교
- ANOVA : 3 개 이상 그룹 평균 차이 검정 → 사후검정 필요
- 카이제곱(χ²) : 범주형 변수 독립성·적합도 검정

(2) 지도학습
- 분류(Classification) : 질적 Y 예측 (ex. 고객 이탈 여부)
- 회귀(Regression) : 양적 Y 예측 (ex. 매출액)

(3) 비지도 학습
- 차원 축소 : 고차원 → 저차원으로 정보 압축 (PCA)
- 군집 분석 : 라벨 없이 비슷한 개체 묶음 (K-means)
- 연관 규칙 : 장바구니 분석처럼 항목 간 동시발생 규칙 탐색

(4) 강화 학습
- Trial & Error 기반 보상 최적화
- Model-free vs. Model-based로 세부 기법 구분

---

## 12.2. 주성분 분석(PCA)
#### PCA?
- **PCA (Principal Component Analysis)**는 여러 개의 **독립 변수들을 요약하여 주요 성분(축)**으로 변환하는 차원 축소 기법
- 원래의 변수들을 **선형 결합**해 주성분을 만들며, **분산이 최대가 되는 방향**을 우선으로 선택함
- 변수 간 **상관관계가 높거나 차원이 많을 때** 차원의 저주(curse of dimensionality)를 방지함

#### 목적
- 차원 축소 : 높은 차원의 데이터를 소수의 성분으로 요약 
- 정보 보존 : 가장 많은 분산(정보)를 담는 축부터 선택 
- 시각화 : 2D 또는 3D로 축소하여 군집 또는 패턴 파악 
- 과적합 방지 : 불필요한 변수 제거로 모델 단순화 

---

#### PCA의 원리

```text
1. 공분산 행렬 계산
2. 고유값 분해 → 고유벡터(축)와 고유값(분산 설명력)
3. 고유값이 큰 순서대로 주성분 선택
4. 기존 데이터를 주성분 축으로 투영
```
---

## 예제 정리 (2차원 데이터)

- 변수 X1, X2에서 **방향이 최대 분산**을 설명하는 축 ⇒ 제1주성분
- **수직 방향**은 그 다음 설명력 ⇒ 제2주성분
- 전체 변수 수가 *p*일 때, 최대 *p*개의 주성분 생성 가능

```text
2차원이면 최대 2개  
제1, 제2 주성분으로 설명력 대부분 포함되면 2개만 선택
```

---

#### 패키지 임포트
```python
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
import pandas as pd
import numpy as np
import seaborn as sns
```

#### 정규화 (스케일링)
```python
df1 = df.drop('Type', axis=1)
scaler = MinMaxScaler()
df_minmax = scaler.fit_transform(df1)
```

> ※ 주성분 분석 전 정규화 필수 (변수 스케일 차이로 인해 분산 과다 반영 방지)

#### PCA 적용
```python
pca = PCA(n_components=9)
df_pca = pca.fit_transform(df_minmax)
explained = np.round(pca.explained_variance_ratio_, 3)
print(explained)
```

```
예시 출력:
array([0.454, 0.18 , 0.126, 0.098, 0.069, 0.042, 0.026, 0.004, 0.  ])
→ 누적 설명력: 100%
```

---

#### 시각화 및 분류 가능성 확인

- 제1주성분과 제2주성분을 **x축, y축**으로 그려서 클래스 분포 확인

```python
pca = PCA(n_components=2)
df_pca = pca.fit_transform(df_minmax)
# 이후 scatter plot으로 시각화 가능
```

```
우리도 biplot의 x, y축이 PCA성분으로 이루어져 있으니 잘 적용해보아야겠다..!
```

## 12.4. 다중공선성 해결과 섀플리 밸류 분석

#### 다중공선성이란?

- **정의**: 두 개 이상의 독립변수 간에 **강한 상관관계**가 있을 때 발생
- **문제점**:
  - 회귀계수의 신뢰도 저하
  - 예측력은 유지되나 **해석력** 약화
  - 변수 제거 시 회귀계수 급변 가능
  - 유의확률(p-value) 왜곡

```text
Ex. 마신 소주의 양과 혈중알코올농도 → 거의 동일한 정보를 가지므로 예측식에서 중복됨
```

---

#### 다중공선성 판단 기준

- 상관계수 : 0.7 이상 → 강한 상관관계 의심 
- **t-통계량** : 작을수록 변수의 설명력이 낮아짐 
- **VIF (Variance Inflation Factor)** : 10 이상이면 심각한 다중공선성 존재 가능 

##### VIF 공식
```math
VIF_k = \frac{1}{1 - R_k^2}
```

- \( R_k^2 \): 변수 k를 종속변수로 보고 나머지 변수로 회귀 분석한 결정계수  
- \( VIF = 10 \) → 표준오차 3.16배 증가  
- \( VIF = 16 \) → 표준오차 4배 증가

---

#### 해결 방법

##### 1. **VIF 기반 변수 제거**
- VIF 값이 **가장 높은 변수 제거**
- 제거 후 다시 VIF 계산 반복

##### 2. **표준화 계수(t-값) 활용**
- t-값이 낮은 변수는 설명력 낮아 제거 우선 고려

##### 3. **변수 결합 또는 축소**
- PCA나 요인분석으로 변수 수를 줄이거나 결합  
- 유사한 의미의 변수 → 대표 변수로 통합

##### 4. **모형 선택법 사용**
- 변수 선택 알고리즘: Forward, Backward, Stepwise Selection  
- 설명력이 낮은 변수 자동 제거

---

#### 새플리 밸류 (Shapley Value)

> 협력게임이론에서 유래한 **기여도 기반 변수 해석 기법**

- 목적: 각 변수의 **설명력 기여도**를 순수하게 측정
- 알고리즘: 조합 가능한 모든 변수 집합에 대해 평균적인 기여도 계산

```text
Ex. x1, x2, x3 → 종속변수 y 설명 시 각 변수의 기여도를 정량적으로 계산
```

## 12.6. Z-test와 T-test

#### Z-test vs T-test

| 구분 | Z-test | T-test |
|------|--------|--------|
| **모분산** | **알려진 경우** | **알려지지 않은 경우** |
| **표본 수** | n ≥ 30일 때 사용 권장 | n < 30 또는 분산 미지시 사용 |
| **활용** | 대규모 집단 비교 | 소규모 집단 또는 정규성 가정 기반 비교 |
| **검정통계량** | Z통계량 | T통계량 |
| **대표 사용** | 비율 검정, 모집단 검정 | 평균 차이 검정, 독립/대응표본 검정 등 |

---

#### 가설 검정 절차

1. **귀무가설(H₀)**, **대립가설(H₁)** 설정
2. **유의수준(α)** 설정 (일반적으로 0.05 사용)
3. **검정 통계량 계산**
4. **p-value 비교 or 임계값 비교** → 귀무가설 기각 여부 결정

##### 단측 vs 양측 검정

| 검정 유형 | 의미 | 귀무/대립가설 예 |
|-----------|------|------------------|
| 양측 검정 | 단순 차이 검정 | H₀: μ₁ = μ₂ / H₁: μ₁ ≠ μ₂ |
| 좌측 단측 | 감소 검정 | H₀: μ₁ ≥ μ₂ / H₁: μ₁ < μ₂ |
| 우측 단측 | 증가 검정 | H₀: μ₁ ≤ μ₂ / H₁: μ₁ > μ₂ |

---

#### 검정 공식

##### 단일 평균 T-test

```math
t = \frac{X - \mu}{S_x / \sqrt{n}}
```

- X: 표본 평균  
- μ: 비교 기준값  
- Sₓ: 표본 표준편차  
- n: 표본 크기

---

##### 두 집단 평균 T-test

```math
t = \frac{X_A - X_B - (\mu_A - \mu_B)}{\sqrt{S_A^2 / n_A + S_B^2 / n_B}}
```

- \(X_A\), \(X_B\): 두 집단 평균  
- \(\mu_A - \mu_B\): 비교 기준 차이 (보통 0)  
- \(S_A^2, S_B^2\): 각 집단의 분산  
- \(n_A, n_B\): 표본 수

---

##### 비율 검정 T-test (단일/이항)

```math
t = \frac{p - \pi}{\sqrt{\pi(1 - \pi) / n}}
```

```math
t = \frac{(p_1 - p_2) - (\pi_1 - \pi_2)}{\sqrt{p_1(1 - p_1) / n_1 + p_2(1 - p_2) / n_2}}
```

- p: 표본 비율  
- π: 가설 기준 비율  
- n: 표본 크기

---

#### 실습 요약

```python
from scipy.stats import shapiro, bartlett
from statsmodels.stats.weightstats import ztest
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
```

##### 분포 시각화

```python
df2 = pd.melt(df)
plt.figure(figsize=(12,6))
sns.boxplot(x='variable', y='value', data=df2)
plt.title('Golf ball test')
plt.show()
```

→ **TypeA_before vs TypeA_after** 비교: 육안상 큰 차이 없음

---

##### 정규성 검정 (Shapiro-Wilk Test)

```python
for col in df.columns:
    print(shapiro(df[col]))
```

→ 대부분 정규성 만족 (p-value > 0.05)

---

##### 등분산 검정 (Bartlett Test)

```python
bartlett(df["TypeA_before"], df["TypeA_after"])
```

→ 등분산성 충족 (p-value > 0.05)

---

##### Z-test 수행

```python
ztest(df["TypeA_before"], x2=df["TypeA_after"], value=0, alternative='two-sided')
```

→ 결과: p-value = 0.218 → **차이 없음**, 귀무가설 기각 불가

---

## 12.7. ANOVA

#### ANOVA 

> **세 집단 이상**의 평균 차이를 비교할 때 사용하는 분산 기반 검정 기법  
> 두 집단은 T-test로 비교 가능하지만, 세 집단 이상에서는 **ANOVA**가 적절

##### 가설 설정

- **귀무가설(H₀)**: 집단 간 평균 차이가 없다  
- **대립가설(H₁)**: 적어도 하나의 집단 평균은 다르다

##### F-분포 사용
- T-test는 **T분포**, ANOVA는 **F분포** 사용
- 그림 12.17 참고 → F분포는 항상 **양의 값**만 가지며 오른쪽으로 긴 꼬리

---

#### ANOVA 분산 해석

- **집단 간 분산 (Between)**: 그룹 간 평균 차이
- **집단 내 분산 (Within)**: 동일 그룹 내 편차
- **총 분산 (Total)** = 집단 간 분산 + 집단 내 분산

### 📐 공식 요약

```math
F = \frac{MS_{Between}}{MS_{Within}} = \frac{SS_{Between} / df_{Between}}{SS_{Within} / df_{Within}}
```

- SS: 제곱합 (Sum of Squares)
- MS: 평균 제곱 (Mean Square)
- df: 자유도 (degrees of freedom)

---

#### 사후 검정 (Post-hoc)

> 유의한 차이가 있는 경우, **어느 집단 간의 차이가 유의한지** 확인하는 추가 검정

##### 대표 기법

- **Turkey’s HSD**: 가장 일반적
- **Scheffe**: 보수적, 보수적 해석에 유리

---

#### 실습 요약약

##### 패키지 임포트트

```python
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
from statsmodels.stats.multicomp import pairwise_tukeyhsd
from scipy import stats
import pandas as pd
```

##### ANOVA 실행

```python
f_statistic, p_val = stats.f_oneway(df['TypeA_before'],
                                    df['TypeB_before'],
                                    df['TypeC_before'])
print(f"F={f_statistic:.2f}, p={p_val:.5f}")
```

→ 예: F=4.2, p=0.01652 → **유의미한 차이 존재**

---

##### 사후 검정 (Turkey’s HSD)

```python
posthoc = pairwise_tukeyhsd(df2['value'], df2['variable'], alpha=0.05)
print(posthoc)
posthoc.plot_simultaneous()
```

→ `TypeA_before` vs `TypeB_before` 간 유의한 차이 존재

---

## 12.8. 카이제곱 검정(교차분석)
#### 카이제곱 검정?

- **명목형 변수 간 독립성** 또는 **연관성** 검정에 사용
- **Crosstabs (교차표)** 형태의 빈도 데이터를 기반으로 검정 수행
- 연속형 변수가 아닌, '성별', '흡연 여부'와 같은 범주형 변수 비교 시 사용

---

#### 카이제곱 통계량 계산 공식

```math
\chi^2 = \sum \frac{(관측값 - 기대값)^2}{기대값}
```

#### 실습: 흡연 여부와 성별 간 독립성 검정

##### 패키지 임포트

```python
from scipy.stats import chi2_contingency
import pandas as pd
import matplotlib.pyplot as plt
```

##### 교차표 생성

```python
crosstab = pd.crosstab(df.sex, df.smoke)
print(crosstab)
```

##### 막대그래프 시각화

```python
crosstab.plot(kind='bar', figsize=(10, 5))
plt.grid()
plt.show()
```

→ 시각적으로도 성별에 따른 흡연 여부 분포 차이 알 수 있음 

---

##### 카이제곱 검정 실행

```python
chiresult = chi2_contingency(crosstab, correction=False)
print('Chi square:', chiresult[0])
print('P-value:', chiresult[1])
```

- p-value = 0.0052  
→ p < 0.05 → **귀무가설 기각**, 성별과 흡연 여부는 통계적으로 유의한 관계 있음

---


<br>
<br>

# 확인 문제

### **문제 1.**
> **🧚 경희는 다트비 교육 연구소의 연구원이다. 경희는 이번에 새롭게 개발한 교육 프로그램이 기존 프로그램보다 학습 성취도 향상에 효과적인지 검증하고자 100명의 학생을 무작위로 두 그룹으로 나누어 한 그룹(A)은 새로운 교육 프로그램을, 다른 그룹(B)은 기존 교육 프로그램을 수강하도록 하였다. 실험을 시작하기 전, 두 그룹(A, B)의 초기 시험 점수 평균을 비교한 결과, 유의미한 차이가 없었다. 8주 후, 학생들의 최종 시험 점수를 수집하여 두 그룹 간 평균 점수를 비교하려고 한다.**   

> **🔍 Q1. 이 실험에서 사용할 적절한 검정 방법은 무엇인가요?**

```
독립표본 T-test
```

> **🔍 Q2. 이 실험에서 설정해야 할 귀무가설과 대립가설을 각각 작성하세요.**

```
귀무가설 : 두 그룹의 최종 시험 점수 평균은 같다.  
대립가설 : 두 그룹의 최종 시험 점수 평균은 다르다.
```

> **🔍 Q3. 검정을 수행하기 위한 절차를 순서대로 서술하세요.**

<!--P.337의 실습 코드 흐름을 확인하여 데이터를 불러온 후부터 어떤 절차로 검정을 수행해야 하는지 고민해보세요.-->

```
1. 두 그룹(A, B)의 최종 시험 점수를 확인한다.  
2. 정규성 검정을 수행한다.  
3. 등분산성 검정을 수행한다.  
4. 정규성 및 등분산성이 만족되면 독립표본 T-test를 실시한다.  
5. 유의수준과 p-value를 비교하여 귀무가설 기각 여부를 판단한다.
```

> **🔍 Q4. 이 검정을 수행할 때 가정해야 하는 통계적 조건을 설명하세요.**

```
독립성, 정규성, 등분산성
```

> **🔍 Q5. 추가적으로 최신 AI 기반 교육 프로그램(C)도 도입하여 기존 프로그램(B) 및 새로운 프로그램(A)과 비교하여 성취도 차이가 있는지 평가하고자 한다면 어떤 검정 방법을 사용해야 하나요? 단, 실험을 시작하기 전, C 그룹의 초기 점수 평균도 A, B 그룹과 유의미한 차이가 없었다고 가정한다.**

```
일원분산분석(ANOVA)
```

> **🔍 Q6. 5번에서 답한 검정을 수행한 결과, 유의미한 차이가 나타났다면 추가적으로 어떤 검정을 수행해 볼 수 있을까요?**

```
Tukey의 HSD
```

---

### **문제 2. 카이제곱 검정**  
> **🧚 다음 중 어떠한 경우에 카이제곱 검정을 사용해야 하나요?   
1️⃣ 제품 A, B, C의 평균 매출 차이를 비교하고자 한다.  
2️⃣ 남성과 여성의 신체 건강 점수 평균 차이를 분석한다.  
3️⃣ 제품 구매 여부(구매/미구매)와 고객의 연령대(10대, 20대, 30대…) 간의 연관성을 분석한다.  
4️⃣ 특정 치료법이 환자의 혈압을 감소시키는 효과가 있는지 확인한다.**  

```
여기에 답을 작성해주세요!
```

### 🎉 수고하셨습니다.